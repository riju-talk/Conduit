# ğŸŒŒ Conduit: The Cosmic Data Orchestrator

Welcome to **Conduit**, a stellar AI-powered system that transforms chaotic data streamsâ€”PDFs, JSONs, and emailsâ€”into structured, actionable insights. Powered by **LangChain**, **FastAPI**, **Redis**, and **Docker**, it classifies intents (Invoice, RFQ, Complaint, Regulation), routes them to specialized agents, and preserves context in a cosmic memory vault. Buckle up for a journey through data galaxies! ğŸš€

## ğŸŒŸ Mission
Conduit tackles diverse inputs with finesse, intelligently classifying their intent, extracting key fields, and storing context for seamless processing. Whether itâ€™s an invoice PDF, a JSON RFQ, or an urgent email complaint, Conduit ensures precision and scalability.

## ğŸ› ï¸ Tech Stack
- **Python**: The backbone for scripting agents and utilities.
- **LangChain**: Orchestrates LLM-driven intent classification and field extraction.
- **FastAPI**: High-performance API for lightning-fast input processing.
- **Redis**: Persistent, warp-speed shared memory for context retention.
- **Docker**: Encapsulates the system for consistent, intergalactic deployment.

## ğŸ‡ Features
- **Intent Classification**: Identifies inputs as Invoice, RFQ, Complaint, or Regulation using AI.
- **Multi-Format Processing**: Handles PDFs, JSONs, and emails with ease.
- **Smart Routing**: Directs inputs to specialized agents based on intent.
- **Data Extraction**: Pulls out intent-specific fields (e.g., invoice number, customer name).
- **Context Memory**: Stores metadata and results in Redis for auditing and chaining.
- **Scalable Deployment**: Runs in Docker for portability and reliability.

## ğŸš€ Flow of Operations
Conduitâ€™s workflow is a cosmic dance of data processing:

1. **Input Arrival**: A user submits a PDF, JSON, or email via FastAPIâ€™s `/process` endpoint.
2. **Classifier Agent**: Analyzes the input, determines its format (PDF, JSON, Email) and intent (Invoice, RFQ, Complaint, Regulation) using LangChain and an LLM (e.g., OpenAIâ€™s GPT).
3. **Routing**: Directs the input to the appropriate agent:
   - JSON â†’ **JSON Agent**
   - PDF/Email â†’ **Email Parser Agent**
4. **Data Extraction**: The chosen agent extracts intent-specific fields (e.g., invoice number for Invoice, issue for Complaint) using LangChain prompts.
5. **Memory Storage**: Metadata (format, intent, timestamp) and extracted fields are stored in Redis for context retention.
6. **Output Delivery**: FastAPI returns the input ID and extracted fields, ready for downstream use.

## ğŸ§  Module Breakdown
Each module is a star in the Conduit constellation, working together to process data with precision.

### ğŸ“¡ Classifier Agent (`agents/classifier.py`)
- **Role**: The mission control, identifying input format and intent, and routing to the correct agent.
- **How It Works**:
  - Detects format: Checks file extensions for PDFs, validates JSON, or assumes Email for text.
  - Classifies intent: Uses LangChainâ€™s `LLMChain` with a prompt like:
    ```
    Classify the intent of this document: {text}
    Possible intents: Invoice, RFQ, Complaint, Regulation
    ```
  - Routes to JSON Agent (for JSON) or Email Parser Agent (for PDF/Email).
  - Stores metadata (format, intent, timestamp) in Redis.
- **Why Itâ€™s Cool**: Acts as the brain, leveraging AI to make smart routing decisions.

### ğŸ“Š JSON Agent (`agents/json_agent.py`)
- **Role**: Extracts fields from JSON inputs based on intent-specific schemas.
- **How It Works**:
  - Parses JSON and selects a schema based on intent (e.g., `["invoice_number", "date"]` for Invoice).
  - Maps JSON keys to schema fields, marking missing fields as `None`.
  - Example: For an RFQ JSON `{"requested_items": ["item1"], "deadline": "2023-12-01"}`, extracts those fields.
- **Why Itâ€™s Cool**: Handles structured data with precision, ensuring no field is left behind.

### âœ‰ï¸ Email Parser Agent (`agents/email_parser.py`)
- **Role**: Extracts fields from unstructured text (PDFs or emails) using AI.
- **How It Works**:
  - Uses LangChainâ€™s `LLMChain` to extract intent-specific fields (e.g., `issue` for Complaint).
  - For emails, extracts additional fields like `sender` and `urgency` with prompts like:
    ```
    Extract the sender name from this text: {text}
    ```
  - Example: From "Hi, Iâ€™m John. Defective product!", extracts `{"customer_name": "John", "issue": "Defective product"}`.
- **Why Itâ€™s Cool**: Tames unstructured text with AI, turning chaos into structured CRM records.

### ğŸ—„ï¸ Shared Memory (`memory.py`)
- **Role**: The cosmic vault, storing context across agents.
- **How It Works**:
  - Uses Redis to store input metadata (format, intent, timestamp) and extracted fields under a unique `input_id`.
  - Example Redis entry: `{"metadata": {"type": "PDF", "intent": "Invoice"}, "extracted_fields": {"invoice_number": "123"}}`.
  - Accessible by all agents for auditing or chaining.
- **Why Itâ€™s Cool**: Redis ensures fast, persistent storage, enabling scalability and context retention.

### ğŸŒ FastAPI (`main.py`)
- **Role**: The galactic gateway, accepting inputs and delivering results.
- **How It Works**:
  - Exposes a `/process` endpoint to handle file uploads (PDFs, JSONs) or text inputs (emails).
  - Calls the Classifier Agent and returns the input ID and extracted fields.
  - Example: `curl -X POST -F "file=@sample_invoice.pdf" http://localhost:8000/process`.
- **Why Itâ€™s Cool**: FastAPIâ€™s async capabilities make it lightning-fast and production-ready.

### ğŸ³ Docker (`Dockerfile`, `docker-compose.yml`)
- **Role**: The spaceship, ensuring consistent deployment across galaxies.
- **How It Works**:
  - `Dockerfile`: Builds a Python environment with dependencies.
  - `docker-compose.yml`: Runs FastAPI and Redis containers, linking them seamlessly.
- **Why Itâ€™s Cool**: Guarantees portability and eliminates "it works on my machine" issues.

## ğŸ“‚ Project Structure
```
Conduit/
â”œâ”€â”€ agents/                # Agent logic
â”‚   â”œâ”€â”€ classifier.py      # Intent classification and routing
â”‚   â”œâ”€â”€ json_agent.py      # JSON processing
â”‚   â””â”€â”€ email_parser.py    # Text extraction
â”œâ”€â”€ data/                  # Sample inputs
â”‚   â”œâ”€â”€ sample_invoice.pdf
â”‚   â”œâ”€â”€ sample_rfq.json
â”‚   â””â”€â”€ sample_email.txt
â”œâ”€â”€ main.py                # FastAPI application
â”œâ”€â”€ memory.py              # Redis-based memory
â”œâ”€â”€ utils.py               # Utility functions
â”œâ”€â”€ Dockerfile             # Docker image configuration
â”œâ”€â”€ docker-compose.yml     # Docker services
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .env                   # Environment variables
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start
### Prerequisites
- Docker & Docker Compose
- Git
- OpenAI API key

### Setup
1. Clone the repo:
   ```bash
   git clone https://github.com/your-username/Conduit.git
   cd Conduit
   ```
2. Create a `.env` file:
   ```
   OPENAI_API_KEY=your-api-key
   REDIS_HOST=redis
   ```
3. Build and run:
   ```bash
   docker-compose up --build
   ```

### Usage
- **Process a File**:
  ```bash
  curl -X POST -F "file=@data/sample_invoice.pdf" http://localhost:8000/process
  ```
- **Process Text**:
  ```bash
  curl -X POST -F "text=From: John Doe\nHi, I have an issue." http://localhost:8000/process
  ```

## ğŸ“Š Sample Outputs
For `sample_invoice.pdf` (Invoice):
```json
{
  "input_id": "123e4567-e89b-12d3-a456-426614174000",
  "extracted_fields": {
    "invoice_number": "123",
    "date": "2023-10-01",
    "total": "$500",
    "items": "[item1, item2]"
  }
}
```

For `sample_email.txt` (Complaint):
```json
{
  "input_id": "456e7890-f12c-34d5-a678-901234567890",
  "extracted_fields": {
    "customer_name": "John Doe",
    "issue": "defective product",
    "sender": "John Doe",
    "urgency": "high"
  }
}
```

## ğŸ§  High-Level Implementation
Conduit is a modular, AI-driven system:
- **Input Handling**: FastAPI accepts files or text, ensuring flexibility.
- **Intent Classification**: LangChain and LLMs (e.g., OpenAI) classify inputs into Invoice, RFQ, Complaint, or Regulation.
- **Agent Specialization**: JSON Agent for structured data, Email Parser for unstructured text, both using intent-specific schemas.
- **Context Persistence**: Redis stores metadata and results, enabling auditing and multi-step processing.
- **Deployment**: Docker ensures seamless, reproducible execution.
- **Scalability**: FastAPIâ€™s async nature and Redisâ€™s performance make it production-ready.

## ğŸ¤ Contributing
Join the mission! Fork the repo, create a feature branch, and submit a PR to enhance the data cosmos.

## ğŸ“„ License
MIT Licenseâ€”see `LICENSE` for details.

ğŸŒŒ **Conduit**: Where data meets destiny.
